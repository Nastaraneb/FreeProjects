{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "\n",
    "!pip install pytextrank\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "import pytextrank\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Dataset loading****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:28:37.294918Z",
     "iopub.status.busy": "2025-04-10T08:28:37.294121Z",
     "iopub.status.idle": "2025-04-10T08:29:10.755380Z",
     "shell.execute_reply": "2025-04-10T08:29:10.754331Z",
     "shell.execute_reply.started": "2025-04-10T08:28:37.294884Z"
    }
   },
   "outputs": [],
   "source": [
    "Validation_data = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\")\n",
    "Train_data = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\n",
    "Test_data = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****A bit of data exploration****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-07T08:16:34.050739Z",
     "iopub.status.busy": "2025-04-07T08:16:34.050391Z",
     "iopub.status.idle": "2025-04-07T08:16:34.074111Z",
     "shell.execute_reply": "2025-04-07T08:16:34.073412Z",
     "shell.execute_reply.started": "2025-04-07T08:16:34.050716Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     0001d1afc246a7964130f43ae940af6bc6c57f01\n",
      "article       By . Associated Press . PUBLISHED: . 14:11 EST...\n",
      "highlights    Bishop John Folda, of North Dakota, is taking ...\n",
      "Name: 0, dtype: object\n",
      "id                     92c514c913c0bdfe25341af9fd72b29db544099b\n",
      "article       Ever noticed how plane seats appear to be gett...\n",
      "highlights    Experts question if  packed out planes are put...\n",
      "Name: 0, dtype: object\n",
      "Describtion <bound method NDFrame.describe of                                               id  \\\n",
      "0       0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
      "1       0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
      "2       00027e965c8264c35cc1bc55556db388da82b07f   \n",
      "3       0002c17436637c4fe1837c935c04de47adb18e9a   \n",
      "4       0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
      "...                                          ...   \n",
      "287108  fffdfb56fdf1a12d364562cc2b9b1d4de7481dee   \n",
      "287109  fffeecb8690b85de8c3faed80adbc7a978f9ae2a   \n",
      "287110  ffff5231e4c71544bc6c97015cdb16c60e42b3f4   \n",
      "287111  ffff924b14a8d82058b6c1c5368ff1113c1632af   \n",
      "287112  ffffd563a96104f5cf4493cfa701a65f31b06abf   \n",
      "\n",
      "                                                  article  \\\n",
      "0       By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
      "1       (CNN) -- Ralph Mata was an internal affairs li...   \n",
      "2       A drunk driver who killed a young woman in a h...   \n",
      "3       (CNN) -- With a breezy sweep of his pen Presid...   \n",
      "4       Fleetwood are the only team still to have a 10...   \n",
      "...                                                   ...   \n",
      "287108  By . James Rush . Former first daughter Chelse...   \n",
      "287109  An apologetic Vanilla Ice has given his first ...   \n",
      "287110  America's most lethal sniper claimed he wished...   \n",
      "287111  By . Sara Malm . PUBLISHED: . 12:19 EST, 8 Mar...   \n",
      "287112  (CNN)Former Florida Gov. Jeb Bush has decided ...   \n",
      "\n",
      "                                               highlights  \n",
      "0       Bishop John Folda, of North Dakota, is taking ...  \n",
      "1       Criminal complaint: Cop used his role to help ...  \n",
      "2       Craig Eccleston-Todd, 27, had drunk at least t...  \n",
      "3       Nina dos Santos says Europe must be ready to a...  \n",
      "4       Fleetwood top of League One after 2-0 win at S...  \n",
      "...                                                   ...  \n",
      "287108  Chelsea Clinton said question of running for o...  \n",
      "287109  Vanilla Ice, 47 - real name Robert Van Winkle ...  \n",
      "287110  America's most lethal sniper made comment in i...  \n",
      "287111  A swarm of more than one million has crossed b...  \n",
      "287112  Other 2016 hopefuls maintain that Bush's annou...  \n",
      "\n",
      "[287113 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Train_data.head()\n",
    "#Test_data.head()\n",
    "print(Train_data.iloc[0])\n",
    "print(Test_data.iloc[0])\n",
    "print(\"Describtion\",Train_data.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning Function\n",
    "\n",
    "In this section, we define a simple text cleaning function called `clean_text()`.  \n",
    "The purpose of this function is to:\n",
    "\n",
    "- Handle missing values (`NaN`)\n",
    "- Remove extra whitespace between words\n",
    "- Remove leading and trailing spaces\n",
    "\n",
    "This helps us ensure that the text data is clean and consistent before applying any further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:29:20.216148Z",
     "iopub.status.busy": "2025-04-10T08:29:20.215859Z",
     "iopub.status.idle": "2025-04-10T08:29:20.222198Z",
     "shell.execute_reply": "2025-04-10T08:29:20.221222Z",
     "shell.execute_reply.started": "2025-04-10T08:29:20.216124Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the input text by:\n",
    "    - Handling missing (NaN) values\n",
    "    - Removing extra spaces\n",
    "    - Trimming leading and trailing spaces\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip()                # Trim leading/trailing spaces\n",
    "    return text\n",
    "test_data = Test_data.copy()\n",
    "test_data['article'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:45:51.137671Z",
     "iopub.status.busy": "2025-04-07T10:45:51.137370Z",
     "iopub.status.idle": "2025-04-07T10:45:51.162065Z",
     "shell.execute_reply": "2025-04-07T10:45:51.161218Z",
     "shell.execute_reply.started": "2025-04-07T10:45:51.137618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🛠️ Using SpaCy's TextRank for Extractive Summarization\n",
    "\n",
    "We load the SpaCy model `en_core_web_lg` and add the TextRank algorithm to it. TextRank helps identify key sentences in the text for extractive summarization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:29:35.119016Z",
     "iopub.status.busy": "2025-04-10T08:29:35.118715Z",
     "iopub.status.idle": "2025-04-10T08:29:37.453757Z",
     "shell.execute_reply": "2025-04-10T08:29:37.453054Z",
     "shell.execute_reply.started": "2025-04-10T08:29:35.118991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x7f97bcd719f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#define the model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# add the textrank algorithm to the model\n",
    "nlp.add_pipe(\"textrank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization with TextRank\n",
    "\n",
    "We summarize each article in the dataset using the TextRank algorithm:\n",
    "\n",
    "- Process each article with an NLP model.\n",
    "- Extract the top 2 most important sentences.\n",
    "- Save the summaries in a new column called `\"processed_text\"`.\n",
    "\n",
    "This helps reduce the size of the articles while keeping their key information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T12:08:22.889106Z",
     "iopub.status.busy": "2025-04-01T12:08:22.888503Z",
     "iopub.status.idle": "2025-04-01T12:38:50.483948Z",
     "shell.execute_reply": "2025-04-01T12:38:50.482445Z",
     "shell.execute_reply.started": "2025-04-01T12:08:22.889079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store processed text\n",
    "processed_articles = []\n",
    "\n",
    "# Iterate over each row in the \"article\" column\n",
    "for text in test_data[\"article\"]:\n",
    "    doc = nlp(text)  # Apply NLP processing\n",
    "    summary = \" \".join([sent.text for sent in doc._.textrank.summary(limit_sentences=2)])\n",
    "    processed_articles.append(summary)\n",
    "\n",
    "# Add the processed text as a new column in the dataframe\n",
    "test_data[\"processed_text\"] = processed_articles\n",
    "\n",
    "# Print an example processed article\n",
    "#print(test_data[\"processed_text\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T12:38:50.485839Z",
     "iopub.status.busy": "2025-04-01T12:38:50.485173Z",
     "iopub.status.idle": "2025-04-01T12:38:50.495273Z",
     "shell.execute_reply": "2025-04-01T12:38:50.493533Z",
     "shell.execute_reply.started": "2025-04-01T12:38:50.485802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee. 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n"
     ]
    }
   ],
   "source": [
    "print(test_data[\"processed_text\"].iloc[0])\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(Test_data[\"article\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstractive Summarization using PEGASUS\n",
    "\n",
    "We use the **PEGASUS** model to generate abstractive summaries, meaning it creates new sentences instead of copying from the text.  \n",
    "PEGASUS is a transformer-based model trained to produce human-like summaries by understanding the main idea of the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install and import important libraries\n",
    "!pip install transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the PEGASUS Model\n",
    "\n",
    "We load the pre-trained **PEGASUS** model and its tokenizer from Hugging Face.\n",
    "\n",
    "- `google/pegasus-cnn_dailymail` is a version fine-tuned for summarizing news articles.\n",
    "- The tokenizer prepares the text input for the model.\n",
    "- The model generates abstractive summaries based on the processed input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:30:04.001944Z",
     "iopub.status.busy": "2025-04-10T08:30:04.001602Z",
     "iopub.status.idle": "2025-04-10T08:30:23.341209Z",
     "shell.execute_reply": "2025-04-10T08:30:23.339822Z",
     "shell.execute_reply.started": "2025-04-10T08:30:04.001915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6394db89427845adace9ad29b435bdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb38040a9234da6ba070a2d6ec57ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c13205622c1465b81667f7ac754d0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e827133bc7148a2a5604091d74fe1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6c08cb30194d49ae593fd6302f10cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60478a771084d0aa912616d479e35fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick the pre_trained model (from huggingface model hub)\n",
    "model_name = \"google/pegasus-cnn_dailymail\"\n",
    "\n",
    "# load the tokenizers\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# define pegasus model\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Articles in Batches\n",
    "\n",
    "To efficiently summarize articles without running into memory issues:\n",
    "\n",
    "- We copy a small subset of the data (first 100 articles) and clean the text.\n",
    "- We move the model to GPU (if available) for faster processing.\n",
    "- We define a batching function that:\n",
    "  - Tokenizes multiple articles at once\n",
    "  - Generates summaries using the PEGASUS model\n",
    "  - Decodes the model outputs back into readable text\n",
    "\n",
    "Finally, we store the generated summaries in a new column called `\"summary\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:42:50.701522Z",
     "iopub.status.busy": "2025-04-10T08:42:50.701070Z",
     "iopub.status.idle": "2025-04-10T08:43:56.765537Z",
     "shell.execute_reply": "2025-04-10T08:43:56.764752Z",
     "shell.execute_reply.started": "2025-04-10T08:42:50.701488Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm  # for showing progress\n",
    "\n",
    "# 1. Use only the first 10 rows to avoid memory problems\n",
    "test_data2 = Test_data.copy().head(100)\n",
    "test_data2['article'] = test_data2['article'].apply(clean_text)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pegasus_model = pegasus_model.to(device)\n",
    "\n",
    "# Batching function\n",
    "def generate_summaries_in_batches(texts, batch_size=4):\n",
    "    summaries = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Generate summaries\n",
    "        with torch.no_grad():\n",
    "            summary_ids = pegasus_model.generate(\n",
    "                **inputs,\n",
    "                max_length=200,  # try a smaller summary length for less memory\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "        # Decode\n",
    "        decoded = [tokenizer.decode(g, skip_special_tokens=True) for g in summary_ids]\n",
    "        summaries.extend(decoded)\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "# Generate summaries\n",
    "summaries = generate_summaries_in_batches(test_data2['article'].tolist(), batch_size=4)\n",
    "\n",
    "# Store results\n",
    "test_data2[\"summary\"] = summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T08:44:07.507100Z",
     "iopub.status.busy": "2025-04-10T08:44:07.506736Z",
     "iopub.status.idle": "2025-04-10T08:44:07.513350Z",
     "shell.execute_reply": "2025-04-10T08:44:07.512607Z",
     "shell.execute_reply.started": "2025-04-10T08:44:07.507055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pigwig the pig fell into a swimming pool in an upmarket neighbourhood .<n>The prize porker was unable to get out of the water and had to be rescued .<n>Firefighters also had to winch a horse out of a swimming pool in West Sussex .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is the moment that a crew of firefighters struggled to haul a giant pig out of a garden swimming pool. The prize porker, known as Pigwig, had fallen into the pool in an upmarket neighbourhood in Ringwood, Hampshire. His owners had been taking him for a walk around the garden when the animal plunged into the water and was unable to get out. A team from Dorset Fire and Rescue struggled to haul the huge black pig out of swimming pool water . The prize porker known as Pigwig had fallen into the water and had then been unable to get out again . Two fire crews and a specialist animal rescue team had to use slide boards and strops to haul the huge black pig from the small pool. A spokesman for Dorset Fire and Rescue Service said: 'At 4.50pm yesterday the service received a call to a pig stuck in a swimming pool. 'One crew of firefighters from Ferndown and a specialist animal rescue unit from Poole were mobilised to this incident. 'Once in attendance the crew secured the pig with strops, and requested the attendance of another appliance which was mobilised from Ringwood by our colleagues in Hampshire Fire and Rescue Service. Firefighters were also called out to a horse which had fallen into a swimming pool in Heyshott, West Sussex . The exhausted animal had to be winched to using an all-terrain crane but appeared no worse for wear after its tumble . 'The crew rescued the pig from the swimming pool using specialist animal rescue slide boards, strops and lines to haul the pig from the swimming pool.' But Pigwig wasn't the only animal who needed rescuing after taking an unexpected swim . Crews in West Sussex were called out to a swimming pool where this time a horse had fallen in. Wet and very bedraggled, the exhausted animal put up no opposition when firefighters arrived to hoist her out of the small garden pool in Heyshott. The two-hour rescue operation ended with the wayward horse being fitted with straps under her belly and lifted up into the air with an all-terrain crane before being swung around and deposited back on dry land. A fire brigade spokesman said that she appeared none the worse for her impromptu swim after stepping over the edge of the domestic pool.\n"
     ]
    }
   ],
   "source": [
    "print(test_data2[\"summary\"].iloc[5])\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(test_data2[\"article\"].iloc[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
